---
title             : "Still suspicious: The suspicious coincidence effect revisited"
shorttitle        : "The suspicious coincidence effect revisited"

author:  
  - name          : "Molly L. Lewis"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    email         : "mollylewis@uchicago.edu"
  - name          : "Michael C. Frank"
    affiliation   : "3"
    email         : "mcfrank@stanford.edu"

affiliation:
  - id            : "1"
    institution   : "Computation Institute, University of Chicago"
  - id            : "2"
    institution   : "Department of Psychology, University of Wisconsin, Madison"
  - id            : "3"
    institution   : "Department of Psychology, Stanford University"


abstract: |
  When learning the meaning of a word, every observed instance is ambiguous between a subordinate meaning (e.g. "dax" means dalmation) and a basic level meaning (e.g. "dax" means dog), yet children and adults successfully learn word meanings at the correct level abstraction. Xu and Tenenbaum (2007a) provide a proposal that resolves this puzzle: learners assume that examples are sampled from the true   underlying category ("strong sampling"), making certain patterns of examples more consistent with a subordinate     meaning than others (the "suspicious coincidence" effect). More recent work (Spencer, Perone, Smith & Samuelson,         2011), however, questions the relevance of this finding by arguing that the effect only occurs when the examples are     presented to the learner simultaneously. Across a series of 12 studies, we systematically manipulate several experimental parameters that vary   between   the previous studies, and successfully replicate the findings of both sets of authors. Taken together, our data suggest that the suspicious coincidence effect in fact is robust to presentation timing of examples, but is sensitive to a confound in Spencer, Perone, Smith, & Samuelson (2011) experiments, namely, trial order. 
  
keywords          : "word learning, Bayesian inference, meta-analysis, concepts"
wordcount         : "1500"

bibliography      : ["r-references.bib"]
header-includes:
  - \usepackage{setspace}
  - \usepackage{float}
  - \usepackage{graphicx}
  - \AtBeginEnvironment{tabular}{\singlespacing}
  - \usepackage{pbox}
  - \usepackage{hyphsubst}

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r load_utility_packages, include = FALSE}
library(papaja)
library(rmarkdown)
library(broom)
library(tidyverse) 
library(langcog)
library(jsonlite)
library(stringr)
library(forcats)
library(knitr)
library(kableExtra)
```

```{r global_options, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      cache = FALSE,
                      fig.pos = "t!")
```


Suppose you are learning a new language and someone tells you that a particular kind of chili pepper is called a "cabai." Does "cabai" mean "chili pepper," "pepper," or "vegetable"? The same object can be referred to by many different labels depending on the level of abstraction -- subordinate (chili), basic level (pepper), or superordinate (vegetable) -- that the speaker wishes to convey. In principle, this ambiguity could pose a challenge for language learners: Even though "cabai" means "chili," in nearly every individual case where "chili" can be used, the speaker could also have been saying "pepper." Yet, despite the apparent difficulty of the learning problem, children quickly and successfully learn words at multiple levels of abstraction [@markman1990constraints].

Xu and Tenenbaum (2007a; henceforth XT) provide an account of how children might make appropriate generalizations about word meaning without relying on negative evidence. They observe that, if "cabai" meant pepper, it would be quite odd for a learner to see several independent examples of a "cabai" that all happened to be chili peppers. Why not a bell pepper? This "suspicious coincidence" might provide evidence that the meaning of "cabai" instead was the narrower subordinate meaning, chili. Formally, this observation emerges from *strong sampling* (Tenenbaum & Griffiths, 2001), the idea that examples of "cabai" are sampled from within the extension of the corresponding concept. So if the word means "pepper" the likelihood of observing a chili pepper three times in a row is low, whereas if the word means "chili" the corresponding likelihood is higher. 

One prediction of this model of generalization is that the observation of more word-object pairs should make a learner more likely to generalize to the subordinate level, as opposed to the basic level. XT tested this prediction by providing adults and children with novel words paired with exemplars at the subordinate level, and found that both groups' generalizations narrowed when they observed three exemplars compared with when they observed only one. This finding was supported by another concurrent set of experiments that suggested that such narrowing was only observed when examples were chosen by an informative teacher [@xu2007b;@lewis2016understanding]. 

These findings have been an important part of a re-evaluation of children's ability to make complex inferences from sparse data, provided the data are produced by an informative sampling process [e.g., strong sampling; @shafto2012]. Children make inferences about ambiguous reference based on the idea that referential descriptions are produced via strong sampling [@frank2014;@horowitz2016]. Subsequent work has found that toddlers' non-linguistic generalization is also consistent with sensitivity to sampling [@xu2009;@gweon2010]. And strong sampling has been used to justify the narrowed generalizations made by preschoolers in pedagogical contexts [@bonawitz2011]. 

The empirical support for the role of strong sampling in XT's paradigm has been questioned, however. In a follow-up study to XT, Spencer, Perone, Smith, and Samuelson (2011; henceforth SPSS) offered an alternative explanation for the suspicious coincidence effect. They argued that the effect can be accounted for by basic memory processes in which the co-occurrence of objects in time and space highlights differences across exemplars, thus leading to increased conceptual discrimination. They predicted that this increased conceptual discrimination should make it more likely for participants to generalize to the subordinate level when more subordinate category exemplars are observed -- precisely the suspicious coincidence pattern observed by XT. 

SPSS tested this possibility by replicating the original XT experiments with slightly different design parameters. Motivated by their theoretical claim, they presented the learning exemplars sequentially, rather than simultaneously, such that only one learning exemplar was visible at a time. The sequential presentation of objects, they argued, more closely reflects the experience of learners in the real world who encounter word-object pairings at distinct points in time and space. In a series of experiments, SPSS replicated XT's main finding -- more basic level generalization with one exemplar than with three exemplars -- with simultaneous presentation, but failed to replicate with sequential presentation. In fact, they observed a reversal under sequential presentation conditions, such that participants were more likely to generalize to the basic level when three subordinate exemplars were presented.

SPSS's findings are important because they call into question one major piece of evidence for the idea that children are sensitive to sampling processes. At the same time, they are also surprising because others have suggested that simultaneous presentation highlights exemplar commonalities and increases memory consolidation [@lawson2014three;@lawson2017influence]. In addition, a closer examination of SPSS's design reveals a number of procedural differences from XT, which -- while seemingly minor -- might have led to the distinct pattern of findings reported by SPSS and XT. 

In light of the importance of the suspicious coincidence effect and the complexity of the empirical picture, our goal in the current work was to replicate the suspicious coincidence effect. Rather than choosing to follow up exclusively on SPSS *or* XT, we chose to explore the space of design decisions that connect them, effectively replicating both paradigms as well as a number of unexplored design variants. By exploring the space of possible procedures more fully we are then able to make strong inferences about the procedural factors responsible for the magnitude of the suspicious coincidence effect.

In the current paper, we report 12 experiments -- 10 pre-registered -- that varied four procedural elements: presentation timing (simultaneous vs. sequential), trial order, blocking of trials, and consistency of labels across trials. To preview our results, we recover the suspicious coincidence effect with a large effect size in both sequential and simultaneous presentation conditions, except under a particular trial order: when the three-exemplar trials are presented *before* the one-exemplar trials. When the three-exemplar trials are presented first, we see a high level of subordinate generalizations even for the one-exemplar trial. We attribute this difference to that fact that, when the three-exemplar trials are presented first, participants are aware of the exemplars from the previous trial, leading learners to not interpret the critical one-exemplar trial as the only observed exemplar. In sum, although we replicate SPSS exactly, our full set of studies leads us to a different interpretation of the data. We conclude that the "suspicious coincidence" effect is robust to sequential presentation. The effect is sensitive to some features of the general experimental context, however, suggesting a potential interpretation in terms of the pragmatics of the task. 

# Methods
We report how we determined our sample size, all manipulations, and all measures in the study. All stimuli, experimental code, sample sizes, and analyses were pre-registered with the exception of Exps. 8 and 12, and all are publicly available (https://osf.io/yekhj/).

## Participants
```{r read_in_data}
### all data
all_d <- read_csv("../data/anonymized_data/all_data_munged_A.csv")

### data with repeat participants excluded
all_d_filtered <- read_csv("../data/anonymized_data/no_dups_data_munged_A.csv")

### key to experiment factors
exp_key <- read_csv("../data/experiment_key.csv") %>%
              mutate(order = gsub("\"", "", order), # this is to deal with excel issues
                     exp = as.character(exp)) %>%
              select(-preregistered) 
```

```{r, get_n_unique_participants}
n_unique <- all_d_filtered %>%
  distinct(exp, subids) %>%
  summarize(n = n())

n_total <- all_d %>%
  distinct(exp, subids) %>%
  summarize(n = n())
  
percent_duplicates <- round((n_total - n_unique)/n_total, 2) * 100
```
Fifty participants were recruited on Amazon Mechanical Turk for each of our 12 experiments (N = 600), and paid 40-50 cents for their participation. Across all 12 experiments, `r percent_duplicates[[1]]`% of participants completed more than one experiment. We report data from all participants in the Main Text, but the pattern of reported findings holds when these participants are excluded (see SI).\footnote{Supplemental information can be found at \url{https://mlewis.shinyapps.io/xtmem_SI/}.}

We determined our sample size on the basis of a pre-registered power calculation using a meta-analytic estimate of the effect size from studies conducted by XT and SPSS. The chosen sample size was approximately twice the estimated sample size necessary to obtain a power of .99 (see SI for details). 

## Stimuli
Our picture stimuli were gathered on the internet, and closely resembled that of XT and SPSS. The linguistic stimuli were 12 one-syllable novel labels (e.g., "wug"), and the referent objects were three sets of 15 pictures from different basic level categories (vegetables, vehicles, and animals). Within each category, five were subordinate exemplars (e.g., green peppers), four were basic level exemplars (e.g., peppers), and six were superordinate exemplars (e.g., vegetables; Fig.\ 1). The exemplars were divided into a learning and generalization set. For each category, the learning set consisted of 3 subordinate, 2 basic, and 2 superordinate pictures presented in different combinations on different trials (see Procedure). The generalization set for each category consisted of the remaining 8 pictures. The learning and generalization sets were the same for all participants.

```{r, out.width = "50%", fig.align = "center", fig.cap = "Sample stimuli from the learning and generalization sets. Three superordinate (top), basic (middle), and subordinate (bottom) exemplars from the vegetable category."}
 
include_graphics("figs/stim.pdf")
```

## Procedure
```{r get_es}
# remap condition values and select relevant conditions
all_d_clean <- all_d %>%
      mutate(condition = as.factor(condition),
             exp = as.character(exp),
             condition = fct_recode(condition,
                                     three_basic = "3bas",
                                     three_subordinate = "3sub",
                                     three_superordinate = "3sup")) %>%
      filter(condition == "one" | condition == "three_subordinate") %>%
      select(exp, everything())

# mean across categories (subject means)
ms <- all_d_clean %>%
  gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
  mutate(value = as.numeric(value)) %>%
  filter(variable == "prop_bas") %>%
  group_by(condition, exp, subids) %>% 
  summarize(value = mean(value))

# means across participants (condition means)
LF_means_wide <- ms %>%
  spread(condition, value) %>%
  group_by(exp) %>%
  summarize(m_one = mean(one),
            sd_one = sd(one),
            m_3sub = mean(three_subordinate),
            sd_3sub = sd(three_subordinate),
            n = n()) %>%
  left_join(exp_key)

LF_effect_sizes <- LF_means_wide %>%
  do(data.frame(d = compute.es::mes(.$m_one, .$m_3sub, .$sd_one,
                     .$sd_3sub, .$n, .$n, verbose = F)$d,
               d_var = compute.es::mes(.$m_one, .$sd_3sub, .$sd_one,
                    .$sd_3sub, .$n, .$n, verbose = F)$var.d)) %>%
  mutate(high = d + (1.96*d_var),
         low = d - (1.96*d_var),
         es_type = "nonpaired",
         exp_recoded = LF_means_wide$exp_recoded) %>%
  left_join(LF_means_wide %>% select(exp_recoded, n)) %>%
  select(exp_recoded, n, everything())
```

Participants were first introduced to a picture of a character ("Mr. Frog") and instructions describing the task. They were told that the character speaks a different language and their job was to help the character find the toys he wants. Participants then advanced to the main task, which consisted of a series of 12 trials on separate screens. On each trial,  one or three learning exemplars from one of the three stimulus categories appeared at the top of the screen, along with the following instructions: "Here [is a wug/are three wugs]. Can you give Mr. Frog all of the other wugs?." Below the learning exemplars, 24 generalization exemplars (8 from each of the 3 categories) were displayed in a 4*x*6 grid. The order of generalization pictures was randomized across trials. Participants were instructed to select the target category members ("To give a wug, click on it below. When you have given all the wugs, click the Next button."). When an exemplar was selected, a red box appeared around the picture, and participants were allowed to change their selections by clicking on the picture a second time. The learning exemplars remained visible at the top of the screen during the generalization task. Once they had made their selections, participants advanced to the next trial by clicking the "Next" button.

There were four trial types distinguished by the number and semantic level of the learning exemplars: one subordinate exemplar, three subordinate exemplars, three basic exemplars, and three superordinate exemplars. Each participant completed each trial type for each of the three stimulus categories (vegetables, vehicles, and animals). 

Across 12 experiments, we manipulated four aspects of the trial design that differed between XT and SPSS (summarized in Table 1): Presentation timing (simultaneous vs. sequential), trial order (1-3 vs. 3-1), label (same vs. different), and blocking (blocked vs. pseudo-random).\footnote{All experiments can be viewed directly in the SI.} We describe each of these factors in more detail below.

### Presentation Timing

Presentation timing was the key, theoretically motivated experimental design difference between experiments by XT (E1 and E2)\footnote{XT E1 and E2 differed in the age of participants (adults vs.\ children), but we collapse across this difference for the present analyses.} and SPSS (E2 and E3). In XT, the learning exemplars were presented statically and simultaneously, while in SPSS, participants saw a sequence of individual exemplars with each exemplar visible only for 1s at a time. In the sequential design, three-exemplar learning trials displayed pictures at three different locations (left, middle, and right) in a sequence that repeated twice, for a total of 6s.

We reproduced these design aspects in the simultaneous and sequential versions of our experiments. In the single-exemplar, sequential trials, the exemplar appeared (1s) and disappeared (1s) for three repetitions \footnote{Our implementation of the sequential design differed slightly from the SPSS design, which did not not include a 1s interval between exemplar presentations. Unfortunately, this difference came to light only in the review process.}. The generalization pictures did not appear in the sequential condition until after the training pictures had appeared for 6 seconds, but remained visible as participants selected generalization exemplars.


```{r}
exp_table <- exp_key %>%
  slice(1:12) %>%
  left_join(LF_effect_sizes) %>%
  mutate(d_string = paste0(d," [", round(low,2), ", ", round(high, 2) , "]"),
         direct_replication_of_string = ifelse(is.na(direct_replication_of),
                                              "", direct_replication_of),
         timing = str_replace_all(timing, "sequential", "seq."),
         timing = str_replace_all(timing, "simultaneous", "simult."),
         blocking = str_replace_all(blocking, "random", "pseudo-random"),
         one_3sub_label = str_replace_all(one_3sub_label, "different", "diff."),
         exp_recoded = as.numeric(exp_recoded)) %>%
  select(exp_recoded, n, timing, order, blocking, 
         one_3sub_label, d_string, direct_replication_of_string) %>%
  arrange(exp_recoded)

kable(exp_table, align = c('c', 'r', 'r', 'r', "r", "r", "r", "r"), 
      caption = "Summary of our 12 experiments.",
      col.names = c("Exp.", "N", "Timing", "Order",
                     "Blocking", "Label", "Effect Size", "Original \nExp."),
      format = "latex", booktabs = TRUE) %>%
    kable_styling(font_size = 12) %>%
    add_header_above(c(" " = 2, "Manipulations" = 4, " ")) %>%
    add_footnote("N = sample size; Timing = presentation timing (sequential or simultaneous); Order = relative ordering of 1 and 3 subordinate trials; Blocking = trials blocked by category or pseudo-random; Label = same or different label in 1 and 3 trials; Effect size = Cohen's d [95% CI]; Original Exp.\ = corresponding experiment from prior literature (XT = Xu & Tenenbaum (2007a); SPSS =   Spencer, et al.\ (2011);  E = Main  Experiment; ES = Supplemental Experiment).", notation = "number", threeparttable = TRUE) 
```





### Trial order

In XT, the three one-subordinate trials occured first followed by all other trial types ("1-3"). In contrast, in SPSS (E2 and E3), the three-subordinate trials occurred first ("3-1"). SPSS's replication of XT's simultaneous design (SPSS E1) showed a single block of either one-subordinate or three-subordinate first (randomized).

### Labels

```{r fig.height = 3, fig.cap = "Mean proportion generalizations to basic level exemplars in the one (blue) and three (red) subordinate exemplar conditions for all 12 of our experiments. Each facet corresponds to a pairing of presentation timing (simultaneous vs. sequential) and trial order (1-3 vs. 3-1). Ranges are bootstrapped 95% confidence intervals."}

# mean across participants with CIS (condition means)
LF_means_long <- ms %>%
  group_by(condition, exp) %>% 
  multi_boot_standard(col = "value")  %>%
  left_join(exp_key)

# relabel conditions for fig
LF_means_long_recoded <- LF_means_long %>%
   ungroup()  %>%
   mutate(exp_recoded = fct_relevel(exp_recoded, as.character(1:12)),
            condition2 = paste(timing, order),
            condition2 = fct_recode(condition2, "sequential \n1-3 order" = "sequential 1-3", 
                                                   "simultaneous \n1-3 order" = "simultaneous 1-3",
                                                   "sequential \n3-1 order" = "sequential 3-1",
                                                   "simultaneous \n3-1 order" = "simultaneous 3-1"),
            condition2 = fct_relevel(condition2, c("simultaneous \n1-3 order", 
                                                   "simultaneous \n3-1 order",
                                                   "sequential \n1-3 order", 
                                                    "sequential \n3-1 order")),
            condition = fct_recode(condition,  "three" = "three_subordinate"),
            condition = fct_relevel(condition, c("one", "three")))

# prop basic means fig
ggplot(LF_means_long_recoded, 
       aes(x = exp_recoded, y = mean, group = condition, fill = condition)) +
  geom_bar(position = "dodge", stat = "identity") +
  geom_linerange(aes(ymin = ci_lower, 
                     ymax = ci_upper), 
                 position = position_dodge(width = .9)) +
  facet_grid(. ~ condition2, scales = "free", drop = TRUE,  space = "free_x") +
  scale_fill_discrete(labels = c("one", "three")) +
  ylim(0, 1) +
  ylab("Prop. basic-level choices") +
  xlab("Experiment") +
  theme_bw() + 
  theme(strip.text = element_text(size = 10),
        strip.background = element_rect(fill = "grey"),
        legend.position = c(0.92, 0.79),
        legend.text = element_text(size = 9),
        legend.title = element_text(size = 10),
        legend.key.size = unit(.5, "cm"),
        legend.background =  element_rect(color = "black", size = 0.5)) +
  ggthemes::scale_fill_solarized()
```


XT used the same label for each category for the three-subordinate and one-subordinate trials (e.g., both the single pepper and the three-pepper trials would be called "wug"; "same"). In contrast, SPSS used a different novel label on each of the 12 trials, such that the three-subordinate and one-subordinate trials were referred to with distinct labels ("different"). We reproduced these two design choices, and also randomized the mapping of labels to categories across trials.

### Blocking

The studies also differed in whether the trials were blocked by trial type: In XT, the first three trials were a block of one-subordinate trials and the remaining 9 were randomized ("pseudo-random"), whereas SPSS blocked all four trial types in all experiments ("blocked"). We also reproduced these two design variants, while randomizing trial order within each block for the blocked design.




```{r get_all_es}
literature_effect_sizes <- read_csv("../data/literature_ES.csv") # see ../analysis/get_literature_ES.R

all_es <- literature_effect_sizes %>%
           bind_rows(LF_effect_sizes) %>%
           left_join(exp_key) %>%
           mutate(source = ifelse(str_detect(exp_recoded, "XT"), "XT2007a", 
                               ifelse(str_detect(exp_recoded, "SPSS"),
                                      "SPSS2011", "LF")), 
                   source = fct_relevel(source, "XT2007a","SPSS2011","LF"),
                   source = as.numeric(source),
                   source = ifelse(source == 2, 3, 
                                   ifelse(source == 3, 5, source)), # playing with scale in plot below
                   timing = fct_relevel(timing,"simultaneous", "sequential"),
                   blocking = fct_recode(blocking, "pseudo-random" = "random"),
                   d_string = paste0(d," [", round(low,2), ", ", round(high, 2) , "]"))
```

```{r get_MA_es}
seq13 <- metafor::rma(d, d_var, dat = filter(all_es, timing == "sequential", order == "1-3"))
seq31 <- metafor::rma(d, d_var, dat = filter(all_es, timing == "sequential", order == "3-1"))
sim13 <- metafor::rma(d, d_var, dat = filter(all_es, timing == "simultaneous", order == "1-3"))
sim31 <- metafor::rma(d, d_var, dat = filter(all_es, timing == "simultaneous", order == "3-1"))

ma_es <- data.frame(
           order = c("1-3 trial order", "3-1 trial order", "1-3 trial order", "3-1 trial order"),
           timing = c("sequential timing", "sequential timing", "simultaneous timing", "simultaneous timing"),
           d = c(seq13$b[[1]], seq31$b[[1]], sim13$b[[1]], sim31$b[[1]]),
           d_low = c(seq13$ci.lb[[1]], seq31$ci.lb[[1]], sim13$ci.lb[[1]], sim31$ci.lb[[1]]),
           d_high = c(seq13$ci.ub[[1]], seq31$ci.ub[[1]], sim13$ci.ub[[1]], sim31$ci.ub[[1]]))
```


```{r fig.width=5.5, fig.height=3.5, fig.cap = "Effect sizes for all 19 studies conducted on the suspicious coincidence effect by XT (Xu & Tenenbaum, 2007a), SPSS (Spencer, et al, 2011), and the current authors. Top facets show experiments in which the single exemplar trial occurred first (1-3); Bottom facets show experiments where the single exemplar trial occurred second (3-1). Left facets show experiments where exemplars were presented simultaneously as in XT; Right facets show experiments where exemplars were presented sequentially as in SPSS. Point color indicates whether the single exemplar and three subordinate exemplars received the same (grey) or different (black) label. Point shape indicates whether trials were blocked by category (circle) or pseudo-random (triangle). Points are jittered along the x-axis for visibility. The red line reflects the meta-analytic estimate of the effect size (for the XT experiments, standard deviations on effect sizes are estimated from the SPSS replication). All ranges are 95% confidence intervals."}

# manual x-axis jittering
offset <- .35
all_es2 <- all_es %>%
  #select(exp_recoded, source, timing, order) %>%
  #arrange(timing, order) %>%
  mutate(source = replace(source, exp_recoded == "SPSS_eS1", 3 - offset),
         source = replace(source, exp_recoded == "SPSS_eS2", 3 + offset),
         source =  replace(source, exp_recoded == "SPSS_e2", 3 - offset),
         source = replace(source, exp_recoded == "SPSS_e3", 3 + offset),
         source = replace(source, exp_recoded == "1", 5 + offset),
         source = replace(source, exp_recoded == "2", 5 - offset), # 3
         source = replace(source, exp_recoded == "8", 5 - offset),
         source = replace(source, exp_recoded == "9", 5 + offset), # 7
         source = replace(source, exp_recoded == "4", 5 - offset),
         source = replace(source, exp_recoded == "5", 5 + offset), #6
         source = replace(source, exp_recoded == "10", 5 - offset),
         source = replace(source, exp_recoded == "11", 5 + offset)) # 12
  
# effect size fig
all_es2 %>%
    mutate(timing = fct_recode(timing, `sequential timing` = "sequential", 
                              `simultaneous timing` =  "simultaneous"),
            order = fct_recode(order, `1-3 trial order` = "1-3", `3-1 trial order` = "3-1")) %>%
  ggplot() +
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = d_low, ymax = d_high), 
            fill = "red", alpha = 0.05, inherit.aes = FALSE, data = ma_es) +
  geom_hline(aes(yintercept = d), data = ma_es, color = "red") +
  geom_hline(yintercept = 0, linetype = 2, color = "black") +
  scale_color_manual(values = c("black","grey63")) +
  # x = jitter(source, 1.5)
  geom_pointrange(aes(x =  source,  y = d, ymax = high, 
                      ymin = low, color = one_3sub_label, shape = fct_rev(blocking)), 
                  size = .4) +
  facet_grid(order ~ timing) +
  scale_x_continuous(breaks = c(1, 3, 5), limits = c(.5, 5.5),
                     labels = c("XT","SPSS","LF")) +
  ylab(expression(paste("Cohen's ", italic("d")))) +
  xlab("Paper") + 
  guides(color = guide_legend( "Label", title.theme = element_text(size = 9, angle = 0)),
         shape = guide_legend( "Blocking", title.theme = element_text(size = 9, angle = 0)))  +
  #theme_bw()  +
  ggthemes::theme_few()  +
  theme(axis.text = element_text(colour = "black"),
        axis.ticks = element_line(colour = "black"),
        strip.text = element_text(size = 9, face = "bold"))


```


## Data analysis

The key prediction of the suspicious coincidence effect is that participants should generalize to the basic level more often in one-subordinate trials relative to three-subordinate trials. To measure this effect, for each trial, we calculated the proportion generalizations to subordinate exemplars within the same category (out of 2) and basic exemplars within the same category (out of 2), and averaged across categories for each participant. We estimated the difference between the one-subordinate and three-subordinate conditions by calculating an effect size (Cohen's *d*) for each experiment. We then estimated the influence of each our design manipulations on the overall effect size by fitting a random-effect meta-analytic model with each of our four manipulations as fixed effects. We used the metafor package [@R-metafor] in R to fit our meta-analytic models.

# Results

Figure 1 shows the mean proportion generalizations to the basic level in the one- and three-subordinate trials for all 12 experiments,\footnote{See SI for means across all measures and conditions.} and Figure 2 shows the corresponding effect sizes (with XT and SPSS experiments included for reference). 


```{r}
# ma model
mod <- metafor::rma(d ~ timing + order + one_3sub_label + blocking, d_var, dat = all_es)
#mod_interact <- metafor::rma(d ~ timing*order, d_var, dat = all_es)


mod_df <- data.frame(fixed_effect = c("Intercept", 
                                        "Simultaneous vs. sequential timing", 
                                        "1-3 vs. 3-1 trial order",
                                        "Different vs. same label", 
                                        "Blocked vs. pseudo-random trial structure"),
                      beta_string = paste0(round(mod$beta, 2), 
                                        " [", round(mod$ci.lb, 2), ", "
                                  , round(mod$ci.ub,2) , "]"),
                      zval = mod$zval,
                      pval_string = round(mod$pval, 2)) %>%
          mutate(pval_string = ifelse(pval_string == 0, "<.0001", pval_string))

# MA model table
kable(mod_df, caption = "Meta-analytic model with manipulations as fixed effects.",
      align = c('l', 'r', 'r', 'r'), digits = 2,
      col.names = c("Fixed effect", "beta", "z-value", "p-value"),
      format = "latex", booktabs = TRUE)  %>%
      kable_styling(font_size = 12) 


## stats for text below
trial_order_string <- mod_df %>%
                      filter(fixed_effect == "1-3 vs. 3-1 trial order") %>%
                      mutate(beta = str_split(beta_string, " ")[[1]][[1]],
                             zval = round(zval, 2),
                             full_string = paste0(" = ", beta, "; *Z* = ", zval,
                                                  "; *p* ", pval_string)) %>%
                      select(full_string)
                      
timing_string <- mod_df %>%
                      filter(fixed_effect == "Simultaneous vs. sequential timing") %>%
                      mutate(beta = str_split(beta_string, " ")[[1]][[1]],
                             zval = round(zval, 2),
                             full_string = paste0(" = ", beta, "; *Z* = ", zval,
                                                  "; *p* = ", pval_string)) %>%
                      select(full_string)

blocking_string <- mod_df %>%
                      filter(fixed_effect == "Blocked vs. pseudo-random trial structure") %>%
                      mutate(beta = str_split(beta_string, " ")[[1]][[1]],
                             zval = round(zval, 2),
                             full_string = paste0(" = ", beta, "; *Z* = ", zval,
                                                  "; *p* = ", pval_string)) %>%
                      select(full_string)

label_string <- mod_df %>%
                      filter(fixed_effect ==  "Different vs. same label") %>%
                      mutate(beta = str_split(beta_string, " ")[[1]][[1]],
                             zval = round(zval, 2),
                             full_string = paste0(" = ", beta, "; *Z* = ", zval,
                                                  "; *p* = ", pval_string)) %>%
                      select(full_string)
```

In two exact replications of the XT method, we replicate the suspicious coincidence effect (Exp. 1: *d* = `r filter(all_es, exp_recoded == "1") %>% select(d_string) %>% unlist()`; Exp. 2: *d* = `r filter(all_es, exp_recoded == "2") %>% select(d_string) %>% unlist()`), with a magnitude comparable to the original XT experiments (XT E1: *d* = `r filter(all_es, exp_recoded == "XT_adults_e1") %>% select(d_string) %>% unlist()`; XT E2: *d* = `r filter(all_es, exp_recoded == "XT_children_e2") %>% select(d_string) %>% unlist()`). We also replicate the reversal in the suspicious coincidence effect observed by SPSS in an exact replication of their method (Exp. 10; *d* = `r filter(all_es, exp_recoded == "10") %>% select(d_string) %>% unlist()`), and with a magnitude comparable to the original experiments (SPSS E2: *d* = `r filter(all_es, exp_recoded == "SPSS_e2") %>% select(d_string) %>% unlist()`; SPSS E3: *d* =  `r filter(all_es, exp_recoded == "SPSS_e3") %>% select(d_string) %>% unlist()`).

Critically, however, the meta-analytic model across all 12 experiments reveals that only trial order is a reliable predictor of effect size ($\beta$ `r trial_order_string[[1]]`), while timing ($\beta$ `r timing_string[[1]]`), blocking ($\beta$ `r blocking_string[[1]]`), and label are not ($\beta$ `r label_string[[1]]`; Table 2). These data thus reveal that the suspicious coincidence is robust to spatio-temporal aspects of the presentation learning exemplars, in contrast to the conclusion drawn by SPSS. In the General Discussion, we consider why trial order might influence the suspicious coincidence effect.

# General Discussion
The ``suspicious coincidence'' effect (Xu & Tenenbaum, 2007a) suggests a powerful mechanism by which learners might overcome the inherent ambiguity associated with learning subordinate word meanings; Other evidence (Spencer, Perone, Smith, & Samuelson, 2011), however, suggests that the effect may occur only under particular learning conditions---namely, when the training exemplars are presented simultaneously to the learner. Across 12 studies, we explored the experimental parameter space of the suspicious coincidence paradigm and successfully replicated the findings from both sets of authors. Taken together, our studies lead us to a different conclusion than SPSS: The suspicious coincidence effect is robust to the presentation timing of exemplars, but is sensitive to order effects. In particular, we only observe the suspicious coincidence effect when the single exemplar trial is presented before the three-exemplar trial.

```{r SC_reversal_GD}
three_one_exps <- all_d_clean %>%
  gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
  mutate(value = as.numeric(value)) %>%
  filter(variable == "prop_bas") %>%
  group_by(condition, exp, subids) %>% 
  summarize(value = mean(value)) %>%
  left_join(exp_key) %>%
  filter(exp_recoded %in% c("4", "5", "6", "10", "11", "12")) %>%
  spread(condition, value, -2:-12)

t_test <- t.test(three_one_exps$one, three_one_exps$three_subordinate, paired = FALSE)
t_statistic <- round(t_test$statistic,2)[[1]]
p_statistic <- round(t_test$p.value, 2)

three_one_exps_wide <- all_d_clean %>%
  gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
  mutate(value = as.numeric(value)) %>%
  filter(variable == "prop_bas") %>%
  group_by(condition, exp, subids) %>% 
  summarize(value = mean(value)) %>%
  left_join(exp_key) %>%
  ungroup() %>%
  filter(exp_recoded %in% c("4", "5", "6", "10", "11", "12"))  %>%
  spread(condition, value) %>%
  summarize(m_one = mean(one),
            sd_one = sd(one),
            m_3sub = mean(three_subordinate),
            sd_3sub = sd(three_subordinate),
            n = n()) 

three_one_effect_size <- three_one_exps_wide %>%
  do(data.frame(d = compute.es::mes(.$m_one, .$m_3sub, .$sd_one,
                     .$sd_3sub, .$n, .$n, verbose = F)$d,
               d_var = compute.es::mes(.$m_one, .$sd_3sub, .$sd_one,
                    .$sd_3sub, .$n, .$n, verbose = F)$var.d)) %>%
  mutate(high = d + (1.96*d_var),
         low = d - (1.96*d_var),
         d_string = paste0(d," [", round(low,2), ", ", round(high, 2) , "]"))

one_three_exps_wide <- all_d_clean %>%
  gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
  mutate(value = as.numeric(value)) %>%
  filter(variable == "prop_bas") %>%
  group_by(condition, exp, subids) %>% 
  summarize(value = mean(value)) %>%
  left_join(exp_key) %>%
  ungroup() %>%
  filter(exp_recoded %in% c("1", "2", "3", "7", "8", "9"))  %>%
  spread(condition, value) %>%
  summarize(m_one = mean(one),
            sd_one = sd(one),
            m_3sub = mean(three_subordinate),
            sd_3sub = sd(three_subordinate),
            n = n()) 

one_three_effect_size <- one_three_exps_wide %>%
  do(data.frame(d = compute.es::mes(.$m_one, .$m_3sub, .$sd_one,
                     .$sd_3sub, .$n, .$n, verbose = F)$d,
               d_var = compute.es::mes(.$m_one, .$sd_3sub, .$sd_one,
                    .$sd_3sub, .$n, .$n, verbose = F)$var.d)) %>%
  mutate(high = d + (1.96*d_var),
         low = d - (1.96*d_var))

ES_diff = one_three_effect_size$d - three_one_effect_size$d
```

The critical difference between the 1-3 and 3-1 ordering was the rate of generalization to the basic level in the one exemplar trial: When the single exemplar trial occurred second, participants generalized to the basic level at a much lower rate than in the reverse order. Why might this ordering matter? We speculate that this difference may be due to the possibility that learners track exemplar frequency across trials, due to the pragmatics of the task. In other words, when the single exemplar trial occurs second, learners may have interpreted this as the *fourth* exemplar from the same subordinate category in a row, rather than a single exemplar. This hypothesis predicts that participants should be less likely to generalize to the basic level on "single" exemplar trials compared to three-subordinate trials under the 3-1 ordering, thus leading to a reversal of the suspicious coincidence effect. We find some evidence to suggest such a reversal in an analysis across all experiments with the 3-1 ordering (*t*(581) = `r t_statistic`; *p* = `r p_statistic`; *d* = `r three_one_effect_size$d_string`).

Our findings highlight the influence of seemingly minor experimental design parameters on the observed pattern of data. In the present studies, experiments with the 1-3 versus 3-1 ordering differed by an effect size of `r ES_diff`---a sizable difference that is likely to invite an unwarranted theoretical explanation. Experimental design parameters are especially important in the context of replication. When conducting a replication of an existing finding, small design parameters may influence the magnitude of the effect [@lewis2016understanding] and even its presence [@phillips2015second]. This sensitivity requires that replicators reproduce the original design with as much fidelity as possible before concluding that an effect fails to replicate. Only then can the effect be explored, and possible confounds and moderators identified. 

In sum, our studies demonstrate that the suspicious coincidence effect is robust to a range of experimental parameters, and adds to a growing body of work suggesting that sampling plays a critical role in learners' ability to make efficient inferences on the basis of sparse data.


\newpage


# References

---
nocite: |
  @spencer2011learning
  @xu2007word
  @tenenbaum2001
...
  

```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
