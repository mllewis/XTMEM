---
title             : "Still suspicious: The suspicious coincidence effect revisited"
shorttitle        : "The suspicious coincidence effect revisited"

author:  
  - name          : "Molly L. Lewis"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : ""
    email         : "mollyllewis@gmail.com"
  - name          : "Michael C. Frank"
    affiliation   : "3"
    email         : "mcfrank@stanford.edu"

affiliation:
  - id            : "1"
    institution   : "Computation Institute, University of Chicago"
  - id            : "2"
    institution   : "Department of Psychology, University of Wisconsin, Madison"
  - id            : "3"
    institution   : "Department of Psychology, Stanford University"


abstract: |
  Imagine hearing someone call a particular dalmatian "a dax." The meaning of the novel noun "dax" is ambiguous between the subordinate meaning (dalmation) and the basic level meaning (dog). Yet both children and adults successfully learn noun meanings at the intended level of  abstraction from similar evidence. Xu and Tenenbaum (2007a) provided an explanation for this apparent puzzle: Learners assume that examples are sampled from the true underlying category ("strong sampling"), making cases where there are more observed exemplars more consistent with a subordinate meaning than cases where there are fewer exemplars (the "suspicious coincidence" effect). More recent work (Spencer, Perone, Smith & Samuelson, 2011) questions the relevance of this finding, however, arguing that the effect only occurs when the examples are presented to the learner simultaneously. Across a series of 12 studies, we systematically manipulate several experimental parameters that vary across previous studies, and successfully replicate the findings of both sets of authors. Taken together, our data suggest that the suspicious coincidence effect in fact is robust to presentation timing of examples, but is sensitive to another factor that varied in the Spencer, Perone, Smith, & Samuelson (2011) experiments, namely, trial order. Our work highlights the influence of pragmatics on behavior in experimental tasks. 
  
keywords          : "word learning, Bayesian inference, meta-analysis, concepts"
wordcount         : ""

bibliography      : ["r-references.bib"]
header-includes:
  - \usepackage{setspace}
  - \usepackage{float}
  - \usepackage{graphicx}
  - \AtBeginEnvironment{tabular}{\singlespacing}
  - \usepackage{pbox}
  - \usepackage{hyphsubst}

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r load_utility_packages, include = FALSE}
library(papaja)
library(rmarkdown)
library(tidyverse) 
library(broom)
library(langcog)  # remotes::install_github("langcog/langcog")
library(knitr)
library(kableExtra)
library(compute.es)
library(ggthemes)
library(metafor)

# XTMEM to do
# Things to fix manually in tex:
# - reverse a and b of tenabuam 2007 files in bibliography
# - check script again
```

```{r global_options, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      cache = FALSE,
                      fig.pos = "t!")
```

```{r printing_helpers}
get_ma_df <- function(model, term_names){
 data.frame(fixed_effect = term_names,
                      beta_string = paste0(round(model$beta, 2), 
                                        " [", round(model$ci.lb, 2), ", "
                                  , round(model$ci.ub,2) , "]"),
                      zval = model$zval,
                      pval_string = round(model$pval, 2)) %>%
          mutate(pval_string = ifelse(pval_string == 0, "<.0001", 
                                      paste0(" = ", pval_string)))
}

get_ma_term_string <- function(model_df, term){
  model_df %>%
     filter(fixed_effect == term) %>%
       mutate(beta = str_split(beta_string, " ")[[1]][[1]],
              zval = round(zval, 2),
              full_string = paste0(" = ", beta, "; *Z* = ", zval,
                                                  "; *p* ", pval_string)) %>%
              select(full_string) %>%
    unlist(use.names = F)
}
```

Suppose you are learning a new language and someone tells you that a particular kind of chili pepper is called a "cabai." Does "cabai" mean "chili pepper," "pepper," or "vegetable"? The same object can be referred to by many different labels depending on the level of abstraction -- subordinate (chili), basic level (pepper), or superordinate (vegetable) -- that the speaker wishes to convey. In principle, this ambiguity could pose a challenge for language learners: Even though "cabai" means "chili," in nearly every individual case where "chili" can be used, the speaker could also have been saying "pepper." Yet, despite the apparent difficulty of the learning problem, children are able to quickly and successfully learn the meanings of words at multiple levels of abstraction [@markman1990constraints; @waxman1992beyond; @waxman1991establishing]. 

Like adults, young children have a bias to both interpret and use words at the basic level of abstraction [e.g., @rosch1976basic; @waxman1990]. A body of experimental work has examined how children might overcome this basic level bias to learn words at different levels of the conceptual hierarchy [@waxman1991establishing; @waxman1992beyond; @waxman1990]. For example, @waxman1990 presented children with three category exemplars from the same level of abstraction (e.g. a collie, a terrier, and a setter), and asked children to generalize to new exemplars of that category. The results suggest that labeling the  category with a novel word helped children to correctly generalize to new category members, but only when the exemplars were superordinate or basic-level matches; when the exemplars were subordinate matches, the presence of a novel label decreased accuracy in generalization, suggesting that subordinate generalizations are particularly difficult for children to learn.

Xu and Tenenbaum (2007a; henceforth XT) provide an account of how learners might make appropriate generalizations in word learning, particularly at the subordinate level. They observe that, if "cabai" meant pepper, it would be quite odd for a learner to see several independent examples of a "cabai" that all happened to be chili peppers. Why not a bell pepper? This "suspicious coincidence" might provide evidence that the meaning of "cabai" instead was the narrower subordinate meaning, chili. Formally, this observation emerges from *strong sampling* (Tenenbaum & Griffiths, 2001), the idea that examples of "cabai" are sampled from within the extension of the corresponding concept. So if the word means "pepper," the likelihood of observing a chili pepper three times in a row is low, whereas if the word means "chili" the corresponding likelihood is higher. 

One prediction of this model of generalization is that observing more word-object pairs should make a learner more likely to generalize to the subordinate level, as opposed to the basic level. Using a paradigm similar to @waxman1990, XT directly tested this prediction by providing adults and children with novel words paired with exemplars at the subordinate level, and found that both groups' generalizations narrowed when they observed three exemplars compared with when they observed only one. This finding was supported by another concurrent set of experiments that suggested that such narrowing was only observed when examples were chosen by an informative teacher (Xu & Tenenbaum 2007b; Lewis & Frank, 2016). 

These findings have been an important part of a re-evaluation of children's ability to make complex inferences from sparse data, provided the data are produced by an informative sampling process [e.g., strong sampling; @shafto2012]. Children make inferences about ambiguous reference based on the idea that referential descriptions are produced via strong sampling [@frank2014;@horowitz2016]. Subsequent work has found that toddlers' non-linguistic generalization is also consistent with sensitivity to sampling [@xu2009;@gweon2010]. And strong sampling has been used to justify the narrowed generalizations made by preschoolers in pedagogical contexts [@bonawitz2011]. 

The empirical support for the role of strong sampling in XT's paradigm has been questioned, however. In a follow-up study to XT, Spencer, Perone, Smith, and Samuelson (2011; henceforth SPSS) offered an alternative explanation for the suspicious coincidence effect. They argued that the effect can be accounted for by basic memory and perceptual processes in which the co-occurrence of objects in time and space leads to direct comparison, which highlights similarities and differences across exemplars [see e.g., @gentner2006]. This highlighting in turn should lead to better memory for the specific shared features of the target category, and to more narrow generalization at test. Specifically, they predicted that better memory for specific shared features should make it more likely for participants to generalize to the subordinate level when multiple subordinate category exemplars are  presented simultaneously -- precisely the suspicious coincidence pattern observed by XT. 

SPSS tested this possibility by replicating the original XT experiments with slightly different design parameters. Motivated by their theoretical claim, they presented the learning exemplars sequentially, rather than simultaneously, such that only one learning exemplar was visible at a time. The sequential presentation of objects, they argued, more closely reflects the experience of learners in the real world who encounter word-object pairings at distinct points in time and space. In a series of experiments, SPSS replicated XT's main finding -- more basic level generalizations with one exemplar than with three exemplars -- with simultaneous presentation, but failed to replicate it with sequential presentation. In fact, they observed a reversal under sequential presentation conditions, such that participants were more likely to generalize to the basic level when three subordinate exemplars were presented.

SPSS's findings are important because they call into question one major piece of evidence for the idea that children and adults are sensitive to sampling processes. At the same time, they are also surprising because others have suggested that simultaneous presentation highlights exemplar commonalities and increases memory consolidation [@lawson2014three;@lawson2017influence]. In addition, a closer examination of SPSS's design reveals a number of procedural differences from XT, which -- while seemingly minor -- might have led to the diverging findings reported by SPSS and XT. 

In light of the importance of the suspicious coincidence effect and the complexity of the empirical picture, our goal in the current work was to replicate the suspicious coincidence effect. Rather than choosing to follow up exclusively on SPSS *or* XT, we chose to explore the space of design decisions that connect them, effectively replicating both paradigms as well as a number of unexplored design variants [cf. @baribault2018]. By exploring the space of possible procedures more fully we are then able to make strong inferences about the procedural factors responsible for the magnitude of the suspicious coincidence effect.

In the current paper, we report 12 experiments -- 10 pre-registered -- that varied four procedural elements: presentation timing (simultaneous vs. sequential), trial order, blocking of trials, and consistency of labels across trials. We recover the suspicious coincidence effect with a large effect size in both sequential and simultaneous presentation conditions, except under a particular trial order: when the three-exemplar trials are presented *before* the one-exemplar trials. When the three-exemplar trials are presented first, we see a high level of subordinate generalizations even for the one-exemplar trial. We attribute this difference to the fact that, when the three-exemplar trials are presented first, participants are aware of the exemplars from the previous trial and consequently do not interpret the single exemplar as the *only* observed exemplar from the target category.  In sum, although we replicate SPSS exactly, our full set of studies leads us to a different interpretation of the data. We conclude that the "suspicious coincidence" effect is robust to sequential presentation. The effect is sensitive to some features of the general experimental context, however, suggesting a potential interpretation in terms of the pragmatics of the task. 

# Methods

We report how we determined our sample size, all manipulations, and all measures in the study. All stimuli, experimental code, sample sizes, and analyses were pre-registered with the exception of Exps. 8 and 12, and all are publicly available (https://osf.io/yekhj/).

## Participants

```{r read_in_data}
### all data
all_d <- read_csv("../data/anonymized_data/all_data_munged_A.csv")

### data with repeat participants excluded (to report %)
all_d_filtered <- read_csv("../data/anonymized_data/no_dups_data_munged_A.csv")

### key to experiment factors
exp_key <- read_csv("../data/experiment_key.csv") %>%
              mutate(order = gsub("\"", "", order), # this deals with excel issues
                     exp = as.character(exp)) %>%
              select(-preregistered) 
```

```{r get_n_unique_participants}
n_unique <- all_d_filtered %>%
  distinct(exp, subids) %>%
  summarize(n = n())

n_total <- all_d %>%
  distinct(exp, subids) %>%
  summarize(n = n())
  
percent_duplicates <- round((n_total - n_unique)/n_total, 2) * 100
```

Fifty participants were recruited on Amazon Mechanical Turk for each of our 12 experiments (N = 600), and paid 40-50 cents for their participation. Across all 12 experiments, `r percent_duplicates[[1]]`% of participants completed more than one experiment. We report data from all participants in the Main Text, but the pattern of reported findings holds when these participants are excluded (see SI).\footnote{Supplemental information can be found at \url{https://mlewis.shinyapps.io/xtmem_SI/}.}

We determined our sample size on the basis of a pre-registered power calculation using a meta-analytic estimate of the effect size from studies conducted by XT and SPSS. The chosen sample size was approximately twice the estimated sample size necessary to obtain a power of .99 (see SI for details). 

## Stimuli

Our picture stimuli were gathered on the internet, and closely resembled that of XT and SPSS. The linguistic stimuli were 12 one-syllable novel labels (e.g., "wug"), and the referent objects were three sets of 15 pictures from different basic level categories (vegetables, vehicles, and animals). Within each category, five were subordinate exemplars (e.g., green peppers), four were basic level exemplars (e.g., peppers), and six were superordinate exemplars (e.g., vegetables; Fig.\ 1). The exemplars were divided into learning and generalization sets. For each category, the learning set consisted of 3 subordinate, 2 basic, and 2 superordinate pictures presented in different combinations on different trials (see Procedure). The generalization set for each category consisted of the remaining 8 pictures. The learning and generalization sets were the same for all participants.

```{r out.width = "90%", fig.align = "center",  fig.cap = "Sample learning and generalization sets. On a given trial, participants saw one or three exemplars of the same level from the learning set, followed by all exemplars from the generalization set (along with the generalization sets from the other categories)."}
 
include_graphics("figs/stim.pdf")
```

## Procedure
```{r get_es}
# remap condition values and select relevant conditions
all_d_clean <- all_d %>%
      mutate(condition = as.factor(condition),
             exp = as.character(exp),
             condition = fct_recode(condition,
                                     three_basic = "3bas",
                                     three_subordinate = "3sub",
                                     three_superordinate = "3sup")) %>%
      filter(condition == "one" | condition == "three_subordinate") %>%
      select(exp, everything())

# mean across categories (subject means)
ms <- all_d_clean %>%
  gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
  filter(variable == "prop_bas") %>%
  group_by(condition, exp, subids) %>% 
  summarize(value = mean(value))

# means across participants (condition means)
LF_means_wide <- ms %>%
  spread(condition, value) %>%
  group_by(exp) %>%
  summarize(m_one = mean(one),
            sd_one = sd(one),
            m_3sub = mean(three_subordinate),
            sd_3sub = sd(three_subordinate),
            n = n()) %>%
  left_join(exp_key)

LF_effect_sizes <- LF_means_wide %>%
  do(data.frame(compute.es::mes(.$m_one, .$m_3sub, .$sd_one,
                     .$sd_3sub, .$n, .$n, verbose = F))) %>%
  select(d, l.d, u.d, var.d) %>%
  rename(high = u.d,
         low = l.d,
         d_var = var.d) %>%
  mutate(exp_recoded = LF_means_wide$exp_recoded) %>%
  left_join(LF_means_wide %>% select(exp_recoded, n)) %>%
  select(exp_recoded, n, everything())
```

Participants were first introduced to a picture of a character ("Mr. Frog") and instructions describing the task. They were told that the character speaks a different language and their job was to help the character find the toys he wants. Participants then advanced to the main task, which consisted of a series of 12 trials on separate screens. On each trial,  one or three learning exemplars from one of the three stimulus categories appeared at the top of the screen, along with the following instructions: "Here [is a wug/are three wugs]. Can you give Mr. Frog all of the other wugs?" Below the learning exemplars, 24 generalization exemplars (8 from each of the 3 categories) were displayed in a 4*x*6 grid. The order of generalization pictures was randomized across trials. Participants were instructed to select the target category members ("To give a wug, click on it below. When you have given all the wugs, click the Next button."). When an exemplar was selected, a red box appeared around the picture, and participants were allowed to change their selections by clicking on the picture a second time. The learning exemplars remained visible at the top of the screen during the generalization task. Once they had made their selections, participants advanced to the next trial by clicking the "Next" button.

There were four trial types distinguished by the number and conceptual level of the learning exemplars: one subordinate exemplar, three subordinate exemplars, three basic exemplars, and three superordinate exemplars. Each participant completed each trial type for each of the three stimulus categories (vegetables, vehicles, and animals). 

Across 12 experiments, we manipulated four aspects of the trial design that differed between XT and SPSS (summarized in Table 1): Presentation timing (simultaneous vs. sequential), trial order (1-3 vs. 3-1), label (same vs. different), and blocking (blocked vs. pseudo-random).\footnote{All experiments can be viewed directly in the SI.} Our set of experiments does not include all possible combinations of these design factors, but all levels are tested in at least one experiment. We describe each of these factors in more detail below.

### Presentation Timing

Presentation timing was the key, theoretically motivated experimental design difference between experiments by XT (E1 and E2)\footnote{XT E1 and E2 differed in the age of participants (adults vs.\ children), but we collapse across this difference for the present analyses.} and SPSS (E2 and E3). In XT, the learning exemplars were presented statically and simultaneously, while in the key conditions from SPSS, participants saw a sequence of individual exemplars with each exemplar visible only for 1s at a time. In the sequential design, three-exemplar learning trials displayed pictures at three different locations (left, middle, and right) in a sequence that repeated twice, for a total of 6s.

We reproduced these design aspects in the simultaneous and sequential versions of our experiments. In the single-exemplar, sequential trials, the exemplar appeared (1s) and disappeared (1s) for three repetitions.\footnote{Our implementation of the sequential design differed slightly from the SPSS design, which did not include a 1s interval between exemplar presentations.} The generalization pictures did not appear in the sequential condition until after the training pictures had appeared for 6 seconds, but remained visible as participants selected generalization exemplars.


```{r}
exp_table <- exp_key %>%
  slice(1:12) %>%
  left_join(LF_effect_sizes) %>%
  mutate(d_string = paste0(d," [", round(low,2), ", ", round(high, 2) , "]"),
         direct_replication_of_string = ifelse(is.na(direct_replication_of),
                                              "", direct_replication_of),
         timing = str_replace_all(timing, "sequential", "seq."),
         timing = str_replace_all(timing, "simultaneous", "simult."),
         blocking = str_replace_all(blocking, "random", "pseudo-random"),
         one_3sub_label = str_replace_all(one_3sub_label, "different", "diff."),
         exp_recoded = as.numeric(exp_recoded)) %>%
  select(exp_recoded, n, timing, order, blocking, 
         one_3sub_label, d_string, direct_replication_of_string) %>%
  arrange(exp_recoded)

kable(exp_table, align = c('c', 'r', 'r', 'r', "r", "r", "r", "r"), 
      caption = "Summary of our 12 experiments.",
      col.names = c("Exp.", "N", "Timing", "Order",
                     "Blocking", "Label", "Effect Size", "Original \nExp."),
      format = "latex", booktabs = TRUE) %>%
    kable_styling(font_size = 12) %>%
    add_header_above(c(" " = 2, "Manipulations" = 4, " ")) %>%
    add_footnote("N = sample size; Timing = presentation timing (sequential or simultaneous); Order = relative ordering of 1 and 3 subordinate trials; Blocking = trials blocked by category or pseudo-random; Label = same or different label in 1 and 3 trials; Effect size = Cohen's d [95% CI]; Original Exp.\ = corresponding experiment from prior literature (XT = Xu & Tenenbaum (2007a); SPSS =   Spencer, et al.\ (2011);  E = Main  Experiment; ES = Supplemental Experiment).", notation = "number", threeparttable = TRUE) 
```

### Trial order

In XT E1, the three one-subordinate trials occurred first followed by all other trial types ("1-3").\footnote{With the exception of XT E2, which used a between-subject design.} In contrast, in the main experiments in SPSS (E2 and E3), the three-subordinate trials occurred first ("3-1"). SPSS's replication of XT's simultaneous design (SPSS E1) showed a single block of either one-subordinate or three-subordinate first (randomized). In supplemental experiments (ES1 and ES2), SPSS directly explored whether trial order influenced the effect size by replicating SPSS E1 with three subordinate trials followed by the single subordinate trials.

### Labels

```{r fig.height = 3, fig.cap = "Mean proportion generalizations to basic level exemplars in the one (blue) and three (red) subordinate exemplar conditions for all 12 of our experiments. Each facet corresponds to a pairing of presentation timing (simultaneous vs. sequential) and trial order (1-3 vs. 3-1). Ranges are bootstrapped 95% confidence intervals."}

# mean across participants with CIS (condition means)
LF_means_long <- ms %>%
  group_by(condition, exp) %>% 
  multi_boot_standard(col = "value")  %>%
  left_join(exp_key)

# relabel conditions for fig
LF_means_long_recoded <- LF_means_long %>%
   ungroup()  %>%
   mutate(exp_recoded = fct_relevel(exp_recoded, as.character(1:12)),
          condition2 = paste(timing, order),
          condition2 = fct_recode(condition2, "sequential \n1-3 order" = "sequential 1-3", 
                                                   "simultaneous \n1-3 order" = "simultaneous 1-3",
                                                   "sequential \n3-1 order" = "sequential 3-1",
                                                   "simultaneous \n3-1 order" = "simultaneous 3-1"),
          condition2 = fct_relevel(condition2, c("simultaneous \n1-3 order", 
                                                   "simultaneous \n3-1 order",
                                                   "sequential \n1-3 order", 
                                                    "sequential \n3-1 order")),
          condition = fct_recode(condition,  "three" = "three_subordinate"),
          condition = fct_relevel(condition, c("one", "three")))

# prop basic means fig
ggplot(LF_means_long_recoded, 
       aes(x = exp_recoded, y = mean, group = condition, fill = condition)) +
  geom_bar(position = "dodge", stat = "identity") +
  geom_linerange(aes(ymin = ci_lower, 
                     ymax = ci_upper), 
                 position = position_dodge(width = .9)) +
  facet_grid(. ~ condition2, scales = "free", drop = TRUE,  space = "free_x") +
  scale_fill_discrete(labels = c("one", "three")) +
  ylim(0, 1) +
  ylab("Prop. basic-level choices") +
  xlab("Experiment") +
  theme_bw() + 
  theme(strip.text = element_text(size = 10),
        strip.background = element_rect(fill = "grey"),
        legend.position = c(0.92, 0.79),
        legend.text = element_text(size = 9),
        legend.title = element_text(size = 10),
        legend.key.size = unit(.5, "cm"),
        legend.background =  element_rect(color = "black", size = 0.5)) +
  ggthemes::scale_fill_solarized()
```

XT used the same label for each category for the three-subordinate and one-subordinate trials (e.g., both the single pepper and the three-pepper trials would be called "wug"; "same"). In contrast, SPSS used a different novel label on each of the 12 trials, such that the three-subordinate and one-subordinate trials were referred to with distinct labels ("different"). We reproduced these two design choices, and also randomized the mapping of labels to categories across trials.

### Blocking

The studies also differed in whether the trials were blocked by trial type: In XT, the first three trials were a block of one-subordinate trials and the remaining 9 were randomized ("pseudo-random"), whereas SPSS blocked all four trial types in all experiments ("blocked"). We also reproduced these two design variants, while randomizing trial order within each block for the blocked design.


```{r get_all_es}
literature_effect_sizes <- read_csv("../data/literature_ES.csv") # see ../analysis/get_literature_ES.R

all_es <- literature_effect_sizes %>%
            bind_rows(LF_effect_sizes) %>%
            left_join(exp_key) %>%
            mutate(source = ifelse(str_detect(exp_recoded, "XT"), "XT2007a", 
                               ifelse(str_detect(exp_recoded, "SPSS"),
                                      "SPSS2011", "LF")), 
                   source = fct_relevel(source, "XT2007a","SPSS2011","LF"),
                   source = as.numeric(source),
                   source = ifelse(source == 2, 3, 
                                   ifelse(source == 3, 5, source)), # plot scale
                   timing = fct_relevel(timing,"simultaneous", "sequential"),
                   blocking = fct_recode(blocking, "pseudo-random" = "random"),
                   d_string = paste0(d," [", round(low,2), ", ", 
                                     round(high, 2) , "]"))
```

```{r get_MA_es}
seq13 <- metafor::rma(d, d_var, dat = filter(all_es, timing == "sequential", order == "1-3"))
seq31 <- metafor::rma(d, d_var, dat = filter(all_es, timing == "sequential", order == "3-1"))
sim13 <- metafor::rma(d, d_var, dat = filter(all_es, timing == "simultaneous", order == "1-3"))
sim31 <- metafor::rma(d, d_var, dat = filter(all_es, timing == "simultaneous", order == "3-1"))

ma_es <- data.frame(
           order = c("1-3 trial order", "3-1 trial order", "1-3 trial order", "3-1 trial order"),
           timing = c("sequential timing", "sequential timing", "simultaneous timing", "simultaneous timing"),
           d = c(seq13$b[[1]], seq31$b[[1]], sim13$b[[1]], sim31$b[[1]]),
           d_low = c(seq13$ci.lb[[1]], seq31$ci.lb[[1]], sim13$ci.lb[[1]], sim31$ci.lb[[1]]),
           d_high = c(seq13$ci.ub[[1]], seq31$ci.ub[[1]], sim13$ci.ub[[1]], sim31$ci.ub[[1]])
         )
```


```{r fig.width=5.5, fig.height=3.5, fig.cap = "Effect sizes for all 19 studies conducted on the suspicious coincidence effect by XT (Xu & Tenenbaum, 2007a), SPSS (Spencer, et al., 2011), and the current authors. Each point corresponds to a study, with study authors on the x-axis and effect size on the y-axis. Facets correspond to different design parameters: Top facets show experiments with single exemplar trial  first (1-3); Bottom facets show experiments with single exemplar trial second (3-1); Left facets show experiments with simultaneous presentation of exemplars, as in XT; Right facets show experiments with sequential presentation of exemplars, as in SPSS. Point color indicates whether the single exemplar and three subordinate exemplars received the same (grey) or different (black) label. Point shape indicates whether trials were blocked by category (circle) or pseudo-random (triangle).  The red line reflects the meta-analytic estimate of the effect size (for the XT experiments, standard deviations on effect sizes are estimated from the SPSS replication). Ranges are 95% confidence intervals. Points are jittered along the x-axis for visibility."}

# manual x-axis jittering
OFFSET <- .35
all_es2 <- all_es %>%
  mutate(source = replace(source, exp_recoded == "XT_children_e2", 1 + OFFSET),
         source = replace(source, exp_recoded == "SPSS_eS1", 3 - OFFSET),
         source = replace(source, exp_recoded == "SPSS_eS2", 3 + OFFSET),
         source = replace(source, exp_recoded == "SPSS_e2", 3 - OFFSET),
         source = replace(source, exp_recoded == "SPSS_e3", 3 + OFFSET),
         source = replace(source, exp_recoded == "1", 5 + OFFSET),
         source = replace(source, exp_recoded == "2", 5 - OFFSET), # 3
         source = replace(source, exp_recoded == "8", 5 - OFFSET),
         source = replace(source, exp_recoded == "9", 5 + OFFSET), # 7
         source = replace(source, exp_recoded == "4", 5 - OFFSET),
         source = replace(source, exp_recoded == "5", 5 + OFFSET), # 6
         source = replace(source, exp_recoded == "10", 5 - OFFSET),
         source = replace(source, exp_recoded == "11", 5 + OFFSET)) # 12
  
# effect size fig
es_fig_data <- all_es2 %>%
    mutate(timing = fct_recode(timing, `sequential timing` = "sequential", 
                              `simultaneous timing` =  "simultaneous"),
            order = fct_recode(order, `1-3 trial order` = "1-3",
                               `3-1 trial order` = "3-1"))

es_fig <- ggplot(es_fig_data) +
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = d_low, ymax = d_high), 
            fill = "red", alpha = 0.05, inherit.aes = FALSE, data = ma_es) +
  geom_hline(aes(yintercept = d), data = ma_es, color = "red") +
  geom_hline(yintercept = 0, linetype = 2, color = "black") +
  scale_color_manual(values = c("black","grey63")) +
  geom_pointrange(aes(x =  source,  y = d, ymax = high, 
                      ymin = low, color = one_3sub_label, shape = fct_rev(blocking)), 
                  size = .4) +
  facet_grid(order ~ timing) +
  scale_x_continuous(breaks = c(1, 3, 5), limits = c(.5, 5.5),
                     labels = c("XT","SPSS","LF")) +
  ylab(expression(paste("Cohen's ", italic("d")))) +
  xlab("Paper") + 
  guides(color = guide_legend( "Label", 
                               title.theme = element_text(size = 9, angle = 0)),
         shape = guide_legend( "Blocking", 
                               title.theme = element_text(size = 9, angle = 0)))  
es_fig +
  theme_bw()  +
  theme(axis.text = element_text(colour = "black"),
        axis.ticks = element_line(colour = "black"),
        strip.text = element_text(size = 9, face = "bold"),
        strip.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        panel.border = element_rect(colour = "black", size=.7))
```

## Data analysis

The key prediction of the suspicious coincidence effect is that participants should generalize to the basic level more often in one-subordinate trials relative to three-subordinate trials. To measure this effect, for each trial, we calculated the proportion generalizations to basic exemplars within the same category (out of 2) and averaged across categories for each participant. We estimated the difference between the one-subordinate and three-subordinate conditions by calculating an effect size for each experiment (Cohen's *d*; see SI for details). We then estimated the influence of each our design manipulations on the overall effect size by fitting a random-effect meta-analytic model with each of our four manipulations as fixed effects. The model included both the present set of experiments as well as prior experiments by XT and SPSS. We used the metafor package [@R-metafor] in R to fit our meta-analytic models.

# Results

Figure 2 shows the mean proportion generalizations to the basic level in the one- and three-subordinate trials for all 12 experiments,\footnote{See SI for means across all measures and conditions.} and Figure 3 shows the corresponding effect sizes (with XT and SPSS experiments included for reference). 


```{r}
# ma_model
mod <- metafor::rma(d ~ timing + order + one_3sub_label + blocking, d_var, dat = all_es)

# get tidy model results
terms <-  c("Intercept", 
            "Simultaneous vs. sequential timing",
            "1-3 vs. 3-1 trial order",
            "Different vs. same label",
            "Blocked vs. pseudo-random trial structure")
mod_df <- get_ma_df(mod, terms)

# MA table for printing
mod_df %>%
  rowwise() %>%
  mutate(pval_string = gsub("\ =", "", pval_string)) %>% # get rid of equal signs
  kable(caption = "Meta-analytic model with manipulations as fixed effects.",
        align = c('l', 'r', 'r', 'r'), digits = 2,
        col.names = c("Fixed effect", "beta", "z-value", "p-value"),
        format = "latex", booktabs = TRUE)  %>%
  kable_styling(font_size = 12) 

# get strings for text:
trial_order_string <- get_ma_term_string(mod_df, "1-3 vs. 3-1 trial order")
timing_string <-  get_ma_term_string(mod_df, "Simultaneous vs. sequential timing")
blocking_string <- get_ma_term_string(mod_df, "Blocked vs. pseudo-random trial structure")
label_string <- get_ma_term_string(mod_df, "Different vs. same label")
```

In two exact replications of the XT method, we replicate the suspicious coincidence effect (Exp. 1: *d* = `r filter(all_es, exp_recoded == "1") %>% select(d_string) %>% unlist()`; Exp. 2: *d* = `r filter(all_es, exp_recoded == "2") %>% select(d_string) %>% unlist()`), with a magnitude comparable to the original XT experiments (XT E1: *d* = `r filter(all_es, exp_recoded == "XT_adults_e1") %>% select(d_string) %>% unlist()`; XT E2: *d* = `r filter(all_es, exp_recoded == "XT_children_e2") %>% select(d_string) %>% unlist()`). We also replicate the reversal in the suspicious coincidence effect observed by SPSS in an exact replication of their method (Exp. 10; *d* = `r filter(all_es, exp_recoded == "10") %>% select(d_string) %>% unlist()`), and with a magnitude comparable to the original experiments (SPSS E2: *d* = `r filter(all_es, exp_recoded == "SPSS_e2") %>% select(d_string) %>% unlist()`; SPSS E3: *d* =  `r filter(all_es, exp_recoded == "SPSS_e3") %>% select(d_string) %>% unlist()`).

Critically, however, the meta-analytic model across all 12 experiments reveals that only trial order is a reliable predictor of effect size ($\beta$ `r trial_order_string`), while timing ($\beta$ `r timing_string`), blocking ($\beta$ `r blocking_string`), and label are not ($\beta$ `r label_string`; Table 2). These data thus suggest that the suspicious coincidence is robust to spatio-temporal aspects of the presentation learning exemplars, in contrast to the conclusion drawn by SPSS. 

```{r interaction_model}
mod_interact <- metafor::rma(d ~ timing*order, d_var, dat = all_es)
mod_interact_df <- get_ma_df(mod_interact, c("intercept", "timing",  "order", "interaction"))

## stats for text below:
int_order_string <- get_ma_term_string(mod_interact_df, "order")
int_timing_string <- get_ma_term_string(mod_interact_df, "timing")
int_interaction_string <- get_ma_term_string(mod_interact_df, "interaction")
```

Our data also suggest that the 3-1 ordering interacts with presentation timing: In experiments with the 3-1 ordering and sequential presentation (Exp.\ 10-12), we see a reversal of the suspicious coincident effect, as observed by SPSS. To examine this pattern, we fit a second meta-analytic model that included presentation timing and trial order as additive effects and a third term for their interaction. As in the initial model, there was a main effect of trial order ($\beta$ `r int_order_string`), but not presentation timing ($\beta$ `r int_timing_string`). However, there was also a significant interaction between the effects of two design parameters ($\beta$ `r int_interaction_string`). This interaction effect is due to increased generalizations to the basic level when the three subordinate trials are presented sequentially (Exp.\ 10-12) compared to simultaneously (Exp.\ 4-6).  In the General Discussion, we consider why trial order might influence the suspicious coincidence effect, and possible reasons for the interaction with presentation timing. 

# General Discussion

The ``suspicious coincidence'' effect (Xu & Tenenbaum, 2007a) suggests a powerful mechanism by which learners might overcome the inherent ambiguity associated with learning subordinate word meanings. Other evidence (Spencer, Perone, Smith, & Samuelson, 2011), however, suggests that the effect may occur only under particular learning conditions -- namely, when the training exemplars are presented simultaneously to the learner. Across 12 studies, we explored the experimental parameter space of the suspicious coincidence paradigm and successfully replicated the findings from both sets of authors. Taken together, our studies lead us to a different conclusion than SPSS: The suspicious coincidence effect is robust to the presentation timing of exemplars, but is sensitive to order effects. These order effects (where three exemplar trials are presented before the one exemplar trials) were not predicted by XT. Below we offer an account of these results based on recent generalizations of strong sampling models to describe pragmatic inferences.

```{r SC_reversal_GD_trial_order}
# calculate effect size for all 3-1 experiments
three_one_exps_wide <- all_d_clean %>%
  gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
  mutate(value = as.numeric(value)) %>%
  filter(variable == "prop_bas") %>%
  group_by(condition, exp, subids) %>% 
  summarize(value = mean(value)) %>%
  left_join(exp_key) %>%
  ungroup() %>%
  filter(exp_recoded %in% c("4", "5", "6", "10", "11", "12"))  %>%
  spread(condition, value) %>%
  summarize(m_one = mean(one),
            sd_one = sd(one),
            m_3sub = mean(three_subordinate),
            sd_3sub = sd(three_subordinate),
            n = n()) 

three_one_effect_size <- three_one_exps_wide %>%
  do(data.frame(d = compute.es::mes(.$m_one, .$m_3sub, .$sd_one,
                     .$sd_3sub, .$n, .$n, verbose = F)$d))

# calculate effect size for all 1-3 experiments
one_three_exps_wide <- all_d_clean %>%
  gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
  mutate(value = as.numeric(value)) %>%
  filter(variable == "prop_bas") %>%
  group_by(condition, exp, subids) %>% 
  summarize(value = mean(value)) %>%
  left_join(exp_key) %>%
  ungroup() %>%
  filter(exp_recoded %in% c("1", "2", "3", "7", "8", "9"))  %>%
  spread(condition, value) %>%
  summarize(m_one = mean(one),
            sd_one = sd(one),
            m_3sub = mean(three_subordinate),
            sd_3sub = sd(three_subordinate),
            n = n()) 

one_three_effect_size <- one_three_exps_wide %>%
  do(data.frame(d = compute.es::mes(.$m_one, .$m_3sub, .$sd_one,
                     .$sd_3sub, .$n, .$n, verbose = F)$d))

# get difference between all 3-1 vs. 1-3 experiments
ES_diff <- one_three_effect_size$d - three_one_effect_size$d
```

The critical difference between the 1-3 and 3-1 ordering was the rate of generalization to the basic level in the one exemplar trial: When the single exemplar trial occurred second, participants were less likely to generalize to the basic level compared to when the single exemplar trial was presented first. Why might this ordering matter? Consider a scenario in which first the learner  observes a trial with three subordinate peppers followed by a second trial with only a single pepper. Although the two trials were intended to be interpreted as independent from each other, their co-occurrence in the task may have suggested to participants that they are pragmatically related, leading participants to track their frequency across trials. If true, when the learner observes the single pepper on the second trial, it is effectively the *fourth* subordinate exemplar from the same category (identical to an exemplars from the three subordinate trials). This account predicts that learners should be less likely to generalize to the basic level when the "single" exemplar is presented second, consistent with our findings. It also makes a second prediction: In the case of the 3-1 ordering, learners should be slightly more likely to generalize to the basic level on the first trial (three exemplars) compared to the second trial (single exemplar, fourth observed exemplar), since seeing four exemplars is a bigger "suspicious coincidence" than three.  We find some evidence consistent with this prediction from the meta-analytic model indicating a reversal of the effect under sequential timing, 3-1 ordering conditions.

While XT's model does not directly predict participants' behavior in the 3-1 ordering, there is a  broader class of Bayesian models, of which XT's model is an instance, that does. These models account for pragmatic reasoning by assuming that speakers reason about the intention of others when making linguistic inferences [e.g., @frank2009a]. In this case, reasoning about the speaker's intention may lead participants to assume discourse continuity across trials. Indeed, there is experimental evidence that children reason about the intention of the speaker to assume discourse continuity when inferring the meaning of a novel word [@horowitz2016]. In future work, the pragmatic influence of discourse continuity in this task can be eliminated by using a between-subject design, as in XT's experiment with children (Xu & Tenenbaum, 2007a; E2).

If indeed participants interpret the one-exemplar trial in 3-1 orders as a fourth exemplar, then it is somewhat surprising that the identity of the label between the two trials does not matter: We see the same pattern when the labels are different (Exp. 10)  as when they are the same (Exp. 11 and 12). Given evidence that children and adults tend to assume that different words have different meanings [@clark1987principle], we might expect that a different label on the one-exemplar trial would lead participants to treat the new exemplar as referring to a new category. However, there are a number a reasons why participants may not have carefully attended to labels across trials. First, participants are never tested on the meaning of labels, and the labels are not directly relevant to completing the generalization task. Second, the three- and one-exemplar trials for the same category rarely occurred adjacent to each other (since the one exemplar trials were always blocked), and this delay might have made it more difficult for participants to remember the labels across the critical trials. Consistent with this pattern, we find  that label identity does not mediate the suspicious coincidence effect across experiments.

We also find that trial order interacts with presentation timing: Replicating SPSS,  sequential presentation in the 3-1 ordering leads to a reversal of suspicious coincidence effect. SPSS's theory predicts the reversal under sequential presentation conditions, but it does not predict the observed interaction with trial order. There is also not a straight-forward explanation from XT's model. We offer one highly speculative account: Sequential presentation conditions may have appeared relatively more complex to participants compared to simultaneous presentation conditions, resulting in higher overall uncertainty in the generalization judgement. This increased uncertainty may have lead participants to be more likely to generalize conservatively---at the basic level---on the first trial when exemplars were presented sequentially as opposed to simultaneously. Future research could test this cognitive load explanation more directly.

Broadly, our findings highlight the influence of seemingly minor experimental design parameters on the observed pattern of data. In the present studies, experiments with the 1-3 versus 3-1 ordering differed by an effect size of `r ES_diff` -- a sizable difference that is likely to invite an unwarranted theoretical explanation. Experimental design parameters are especially important in the context of replication. When conducting a replication of an existing finding, small design parameters may influence the magnitude of the effect [@lewis2016understanding] and even its presence [@phillips2015second]. This sensitivity requires that replicators reproduce the original design with as much fidelity as possible before concluding that an effect fails to replicate. Only then can the effect be explored, and possible confounds and moderators identified. 

Both XT's and SPSS's work address an important puzzle in psychological sciences: How do learners learn concepts at multiple levels of abstraction? Their work focuses on a simplified version of this puzzle where the learner must determine the corresponding labels to known concepts. Our findings here support the idea that they solve this puzzle via probabilistic inferences about the level of abstraction that is most likely given the observed data (the original "suspicious coincidence" effect). Importantly, by assuming that trials are non-independent, our interpretation is consistent not only with the original XT set of findings, but also with the observed trial order effects. Our data add to the growing body of work suggesting that suspicious coincidence effects may arise during pragmatic reasoning in language comprehension [@frank2014; @goodman2016] as well as through non-linguistic reasoning [@shafto2012]. Such probabilistic reasoning is likely to play a critical role in learners' ability to make efficient inferences on the basis of sparse linguistic data.

\newpage

# References

---
nocite: |
  @spencer2011learning
  @xu2007word
  @tenenbaum2001
  @xu2007b
  @lewis2016understanding. 
...
  
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
