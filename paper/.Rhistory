other evidence relevant on this replicatione
Our current paper reports 12 experiments, 10 of which were pre-registered. We recover the suspicious coincidence effect with a large effect size in both sequential and simultaneous presentation conditions. The effect only occurs, however, in experiments where the trial with one exemplar is presented *before* the key trial with three subordinate-consistent exemplars (the "suspicious coincidence"). We attribute this difference to participants' awareness of the possibility of subordinate generalizations following the three-exemplar trial; in these conditions, we see a high level of subordinate generalizations even for the one-exemplar trial (leading to the absence of a difference between conditions). In sum, and contra SPSS, the "suspicious coincidence" effect is robust to sequential presentation. The effect is sensitive to some features of the general experimental context, however, suggesting a potential interpretation in terms of the pragmatics of the task.
# Methods
We report how we determined our sample size, all manipulations, and all measures in the study. All stimuli, experimental code, sample sizes, and analyses were pre-registered with the exception of Exps. 4 and 8, and publically available (https://osf.io/yekhj/).
## Participants
```{r read_in_data}
### all data
all_d <- read_csv("../data/anonymized_data/all_data_munged_A.csv")
### data with repeat participants excluded
all_d_filtered <- read_csv("../data/anonymized_data/no_dups_data_munged_A.csv")
## key to experiment factors
exp_key <- read_csv("../data/experiment_key.csv") %>%
mutate(order = gsub("\"", "", order))# this is because excel is dumb, grrr
```
```{r, get_n_unique_participants}
n_unique <- all_d_filtered %>%
distinct(exp, subids) %>%
summarize(n = n())
n_total <- all_d %>%
distinct(exp, subids) %>%
summarize(n = n())
percent_duplicates <- round((n_total - n_unique)/n_total, 2) * 100
```
Fifty participants were recruited on Amazon Mechanical Turk for each of our 12 experiments (N = 600), and paid 40-50 cents for their participation. Across all 12 experiments, `r percent_duplicates[[1]]`% of participants completed more than one experiment. We report data from all participants in the Main Text, but the pattern of reported findings holds when these participants are excluded (see SI)\footnote{Supplemental information can be found at [https://mlewis.shinyapps.io/xtmem_SI/](https://mlewis.shinyapps.io/xtmem_SI/)}.
We determined our sample size on the basis of a pre-registered power calculation using a meta-analytic estimate of the effect size from studies conducted by XT and SPSS. The chosen sample size was approximately twice the estimated sample size necessary to obtain a power of 1.
```{r, out.width = "50%", fig.align = "center", fig.cap = "Sample stimuli. Three superodinate (top), basic (middle), and subordinate (bottom) exemplars from the vegetable category."}
include_graphics("figs/stim.pdf")
```
## Stimuli
Our stimuli closely replicated that of XT and SPSS. The linguistic stimuli were 12 one-syllable novel labels (e.g., "wug"), and the referent objects were three sets of 15 pictures from different basic level categories (vegetables, vehicles and animals). Within each category, five were subordinate exemplars (e.g. green pepper), four were basic level exemplars (e.g. peppers), and six were superordinate exemplars (e.g. vegetables; Fig.\ 1). The exemplars were divided into a learning and generalization set. For each category, the learning set consisted of 3 subordinate, 2 basic, and 2 superordinate pictures presented in different combinations on different trials (see Procedure). The generalization set for each category consisted of the remaining 8 pictures. The learning and generalization sets were the same for all participants.
## Procedure
```{r get_es}
# remap condition values and select relevant conditions
all_d_clean <- all_d %>%
mutate(condition = as.factor(condition),
exp = as.character(exp),
condition = fct_recode(condition,
three_basic = "3bas",
three_subordinate = "3sub",
three_superordinate = "3sup")) %>%
filter(condition == "one" | condition == "three_subordinate") %>%
select(exp, everything())
# mean across categories (subject means)
ms <- all_d_clean %>%
gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
mutate(value = as.numeric(value)) %>%
filter(variable == "prop_bas") %>%
group_by(condition, exp, subids) %>%
summarize(value = mean(value))
# means across participants (condition means)
LF_means_wide <- ms %>%
spread(condition, value) %>%
group_by(exp) %>%
summarize(m_one = mean(one),
sd_one = sd(one),
m_3sub = mean(three_subordinate),
sd_3sub = sd(three_subordinate),
n = n()) %>%
left_join(exp_key)
LF_effect_sizes <- LF_means_wide %>%
do(data.frame(d = compute.es::mes(.$m_one, .$m_3sub, .$sd_one,
.$sd_3sub, .$n, .$n, verbose = F)$d,
d_var = compute.es::mes(.$m_one, .$sd_3sub, .$sd_one,
.$sd_3sub, .$n, .$n, verbose = F)$var.d)) %>%
mutate(high = d + (1.96*d_var),
low = d - (1.96*d_var),
es_type = "nonpaired",
exp_recoded = LF_means_wide$exp_recoded) %>%
left_join(LF_means_wide %>% select(exp_recoded, n)) %>%
select(exp_recoded, n, everything())
LF_effect_sizes
(.64 -.18)/sqrt((.15 +.09)/2)
setwd("~/Documents/research/Projects/XTMEM/paper/SI")
```{r read_in_anon_data}
# this data has been pre-processed with analysis/munge_anonymize_data.R script
all_d <- read_csv("data/anonymized_data/all_data_munged_A.csv") %>%
mutate(condition = fct_recode(condition,
"1 sub." = "one",
"3 basic"= "three_basic",
"3 sub." = "three_subordinate",
"3 super." = "three_superordinate",
"3 basic" = "3bas",
"3 super." = "3sup",
"3 sub." = "3sub"),
condition = fct_relevel(condition, "1 sub.", "3 sub.", "3 basic", "3 super."))
exp_key <- read_csv("data/experiment_key.csv") %>%
mutate(order = gsub("\"", "", order))
```
all_d_clean <- all_d %>%
mutate(condition = as.factor(condition),
exp = as.character(exp),
condition = fct_recode(condition,
three_basic = "3bas",
three_subordinate = "3sub",
three_superordinate = "3sup")) %>%
filter(condition == "one" | condition == "three_subordinate") %>%
select(exp, everything())
all_d_clean <- all_d %>%
mutate(condition = as.factor(condition),
exp = as.character(exp)) %>%
filter(condition == "one" | condition == "three_subordinate") %>%
select(exp, everything())
all_ms_subj2 <- all_d_clean %>%
left_join(exp_key %>% select(exp, exp_recoded)) %>%
select(-exp) %>%
gather(variable, value, c(prop_sub, prop_bas, prop_sup))  %>%
group_by(condition, category, variable, exp_recoded, subids) %>%
mutate(value = as.numeric(value)) %>%
summarize(value = mean(value)) %>%
filter(condition == "one" | condition == "three_subordinate",
variable == 'prop_bas') %>%
spread(condition, value) %>%
ungroup()  %>%
select(-variable)
all_ms_subj2 <- all_d_clean %>%
left_join(exp_key %>% select(exp, exp_recoded)) %>%
select(-exp) %>%
gather(variable, value, c(prop_sub, prop_bas, prop_sup))  %>%
group_by(condition, category, variable, exp_recoded, subids) %>%
mutate(value = as.numeric(value)) %>%
summarize(value = mean(value)) %>%
filter(condition == "one" | condition == "three_subordinate",
variable == 'prop_bas')
all_ms_subj2
all_d_clean <- all_d %>%
mutate(condition = as.factor(condition),
exp = as.character(exp)) %>%
filter(condition == "1 sub." | condition == "3 sub.") %>%
select(exp, everything())
all_d_clean
all_ms_subj_cat <- all_d_clean %>%
left_join(exp_key %>% select(exp, exp_recoded)) %>%
select(-exp) %>%
gather(variable, value, c(prop_sub, prop_bas, prop_sup))  %>%
group_by(condition, category, variable, exp_recoded, subids) %>%
mutate(value = as.numeric(value)) %>%
summarize(value = mean(value)) %>%
filter(variable == 'prop_bas') %>%
spread(condition, value) %>%
ungroup()  %>%
select(-variable)
LF_means_cat <- all_ms_subj_cat %>%
group_by(exp_recoded, category) %>%
summarize(m_one = mean(one),
sd_one = sd(one),
m_3sub = mean(three_subordinate),
sd_3sub = sd(three_subordinate),
n = n())
all_d_clean %>%
left_join(exp_key %>% select(exp, exp_recoded)) %>%
select(-exp) %>%
gather(variable, value, c(prop_sub, prop_bas, prop_sup))  %>%
group_by(condition, category, variable, exp_recoded, subids) %>%
mutate(value = as.numeric(value)) %>%
summarize(value = mean(value)) %>%
filter(variable == 'prop_bas') %>%
spread(condition, value) %>%
ungroup()  %>%
select(-variable)
LF_effect_sizes_cat <- LF_means_cat %>%
ungroup() %>%
do(data.frame(d = mes(.$m_one, .$m_3sub, .$sd_one,
.$sd_3sub, .$n, .$n, verbose = F)$d,
d_var = mes(.$m_one, .$sd_3sub, .$sd_one,
.$sd_3sub, .$n, .$n, verbose = F)$var.d)) %>%
mutate(high = d + (1.96*d_var),
low = d - (1.96*d_var),
es_type = "nonpaired",
exp_recoded = LF_means_cat$exp_recoded,
category = LF_means_cat$category)
LF_means_cat <- all_ms_subj_cat %>%
group_by(exp_recoded, category) %>%
summarize(m_one = mean(`1 sub.`),
sd_one = sd(`1 sub.`),
m_3sub = mean(`3 sub.`),
sd_3sub = sd(`3 sub.`),
n = n())
n = n())
LF_effect_sizes_cat <- LF_means_cat %>%
ungroup() %>%
do(data.frame(d = mes(.$m_one, .$m_3sub, .$sd_one,
.$sd_3sub, .$n, .$n, verbose = F)$d,
d_var = mes(.$m_one, .$sd_3sub, .$sd_one,
.$sd_3sub, .$n, .$n, verbose = F)$var.d)) %>%
mutate(high = d + (1.96*d_var),
low = d - (1.96*d_var),
es_type = "nonpaired",
exp_recoded = LF_means_cat$exp_recoded,
category = LF_means_cat$category)
?kableExtra
?kable
?kable
all_d %>%
filter(exp == 1) %>% # we only want exp 1
filter(condition == "1 sub." | condition == "3 sub.") %>% # we only care about these conds. for the calculating d
gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
filter(variable == "prop_bas") %>% # we only care about this DV for calculating d
group_by(condition, subids) %>%
summarize(value = mean(value)) %>% # get the mean for each subjects across trials
group_by(condition) %>%
summarize(mean_prop_bas = mean(value),
var_prop_bas = var(value)) # get the mean for each condition acros subjects
?xtable
xtable(es_1_calc)
library(xtable)
xtable(es_1_calc)
?kable_styling
head(all_d)
head(exp_table)
exp_key %>%
slice(1:12) %>%
mutate(direct_replication_of_string = ifelse(is.na(direct_replication_of),
"", direct_replication_of),
blocking = str_replace_all(blocking, "random", "pseudo-random"),
one_3sub_label = str_replace_all(one_3sub_label, "different", "diff."),
exp_recoded = as.numeric(exp_recoded)) %>%
select(exp_recoded, timing, order, blocking,
one_3sub_label, direct_replication_of_string) %>%
arrange(exp_recoded)
exp_key
read_csv("data/experiment_key.csv") %>%
mutate(order = gsub("\"", "", order),
exp = as.numeric(exp))
exp_key <- read_csv("data/experiment_key.csv") %>%
mutate(order = gsub("\"", "", o
exp_key <- read_csv("data/experiment_key.csv") %>%
mutate(order = gsub("\"", "", order),
exp = as.numeric(exp))
```
exp_table <- exp_key %>%
slice(1:12) %>%
mutate(direct_replication_of_string = ifelse(is.na(direct_replication_of),
"", direct_replication_of),
blocking = str_replace_all(blocking, "random", "pseudo-random"),
one_3sub_label = str_replace_all(one_3sub_label, "different", "diff."),
exp_recoded = as.numeric(exp_recoded)) %>%
select(exp_recoded, timing, order, blocking,
one_3sub_label, direct_replication_of_string) %>%
arrange(exp_recoded)
```
es_1_calc <- all_d %>%
left_join(exp_key %>% select(exp, exp_recoded)) %>%
filter(exp_recoded == 1) %>% # we only want exp 1
filter(condition == "1 sub." | condition == "3 sub.") %>% # we only care about these conds. for the calculating d
gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
filter(variable == "prop_bas") %>% # we only care about this DV for calculating d
group_by(condition, subids) %>%
summarize(value = mean(value)) %>% # get the mean for each subjects across trials
group_by(condition) %>%
summarize(mean_prop_bas = mean(value),
var_prop_bas = var(value)) # get the mean for each condition acros subjects
head(all_d)
head(exp_key)
read_csv("data/experiment_key.csv") %>%
mutate(order = gsub("\"", "", order),
exp = as.numeric(exp))
exp_key <- read_csv("data/experiment_key.csv") %>%
mutate(order = gsub("\"", "", order),
exp = as.numeric(exp))
```
exp_key
all_d %>%
left_join(exp_key %>% select(exp, exp_recoded))
```{r}
es_1_calc <- all_d %>%
left_join(exp_key %>% select(exp, exp_recoded)) %>%
filter(exp_recoded == 1) %>% # we only want exp 1
filter(condition == "1 sub." | condition == "3 sub.") %>% # we only care about these conds. for the calculating d
gather(variable, value, c(prop_sub, prop_bas, prop_sup)) %>%
filter(variable == "prop_bas") %>% # we only care about this DV for calculating d
group_by(condition, subids) %>%
summarize(value = mean(value)) %>% # get the mean for each subjects across trials
group_by(condition) %>%
summarize(mean_prop_bas = mean(value),
var_prop_bas = var(value)) # get the mean for each condition acros subjects
raw_d <- read_csv("data/anonymized_data/all_raw_A.csv")
raw_d %>%
left_join(exp_key %>% select(exp, exp_recoded, timing)) %>%
mutate(exp_recoded = fct_relevel(exp_recoded, "10", after = 11),
exp_recoded = fct_relevel(exp_recoded, "11", after = 11),
exp_recoded = fct_relevel(exp_recoded, "12", after = 11)) %>%
select(-exp) %>%
ungroup()
```
raw_d_munged <- raw_d %>%
left_join(exp_key %>% select(exp, exp_recoded, timing)) %>%
mutate(exp_recoded = fct_relevel(exp_recoded, "10", after = 11),
exp_recoded = fct_relevel(exp_recoded, "11", after = 11),
exp_recoded = fct_relevel(exp_recoded, "12", after = 11)) %>%
select(-exp) %>%
ungroup()
```
mean(as.numeric(as.character(age))
mean_age <- as.numeric(as.character(raw_d_munged$age, na.rm = T))
mean_age <- as.numeric(as.character(raw_d_munged$age, na.rm = T))
mean_age
mean_age <- mean(as.numeric(as.character(raw_d_munged$age)), na.rm = T)
mean_age
setwd("~/Documents/research/Projects/conVar/paper_figures/dutch_eng_association_plot")
# plot bar graph of association weights of cheese and ear in dutch and english
library(tidyverse)
library(forcats)
### read in data - these are all from Gary
### ENGLISH ASSOCIATIONS
eng_raw = read_csv("data/correlation-swow/correlation_full_en.csv") %>%
select(-1) %>%
mutate(language = "English")
# this isn't critical
dutch_dict <- read_csv("data/mmc2.csv") %>%
select(Word, Translation) %>%
filter(Translation != "") %>%
mutate(Translation = tolower(Translation))
### DUTCH ASSOCATIONS ASSOCIATIONS
nl_raw = read_csv("data/correlation-swow/correlation_full_nl.csv") %>%
select(-1) %>%
mutate(language = "Dutch") %>%
left_join(dutch_dict, by = c("cue" = "Word")) %>%
rename(cue_eng = Translation) %>%
left_join(dutch_dict, by = c("target" = "Word")) %>%
rename(target_eng = Translation)
# My translated list of top 10 associations
MIN_RANK <- 11
my_dict <- read_csv("data/final_associations.csv")
#### JEALOUSY PLOT
target_word <- "jealousy"
current_dict = my_dict %>%
filter(equiv_index_1 < MIN_RANK,
item == target_word) %>%
select(-equiv_index_1) %>%
distinct()
target_words <- filter(current_dict, item == target_word)
eng_plot <-  get_eng_plot_data(eng_raw, current_dict, target_word, target_words)
nl_plot <- get_nl_plot_data(nl_raw, current_dict, target_word, target_words)
plot_data <- eng_plot %>%
bind_rows(nl_plot) %>%
mutate(target = as.factor(target))  %>%
mutate(target = fct_relevel(target, rev(c("envy", "green/green-eyed", "anger/rage", "hate/hatred", "love", "woman/women/wife",
"emotion", "relationship", "bad", "man", "argument"))),
target = fct_recode(target,
"envy \n (afgunst/nijd)" = "envy",
"green(-eyed) \n (groen)" = "green/green-eyed" ,
"anger/rage \n (woede)" = "anger/rage",
"hate/hatred \n (haat)" = "hate/hatred" ,
"love \n (liefde)" = "love" ,
"woman/wife \n (vrouw(en))" = "woman/women/wife",
"emotion \n (emotie)" = "emotion" ,
"relationship \n (relatie)" = "relationship" ,
"bad \n (slecht)" = "bad",
"man \n (man)" = "man",
"argument \n (ruzie)" = "argument"),
language = fct_rev(language))
pdf("jealousy.pdf", width = 8, height = 4.6)
ggplot(plot_data,
aes(x = target, y = swow_normalized,
fill = target)) +
geom_bar(stat = "identity") +
facet_grid(~language) +
coord_flip() +
theme_minimal() +
theme(legend.position = "none",
axis.text.y = element_text(size = 7)) +
ggtitle("jealousy (jaloezie)") +
ylab("normalized conditional probability") +
xlab("word association")
dev.off()
plot bar graph of association weights of cheese and ear in dutch and english
library(tidyverse)
library(forcats)
### read in data - these are all from Gary
### ENGLISH ASSOCIATIONS
eng_raw = read_csv("data/correlation-swow/correlation_full_en.csv") %>%
select(-1) %>%
mutate(language = "English")
# this isn't critical
dutch_dict <- read_csv("data/mmc2.csv") %>%
select(Word, Translation) %>%
filter(Translation != "") %>%
mutate(Translation = tolower(Translation))
### DUTCH ASSOCATIONS ASSOCIATIONS
nl_raw = read_csv("data/correlation-swow/correlation_full_nl.csv") %>%
select(-1) %>%
mutate(language = "Dutch") %>%
left_join(dutch_dict, by = c("cue" = "Word")) %>%
rename(cue_eng = Translation) %>%
left_join(dutch_dict, by = c("target" = "Word")) %>%
rename(target_eng = Translation)
# My translated list of top 10 associations
MIN_RANK <- 11
my_dict <- read_csv("data/final_associations.csv")
get_eng_plot_data <- function(eng_raw, current_dict, target_word, target_words){
eng_plot <- eng_raw %>%
filter(cue == target_word) %>%
filter(target %in% target_words$english) %>%
left_join(current_dict %>%  # get all dutch translation
select(english, equiv_index_1_name) %>% distinct(),
by = c("target" = "english")) %>%
mutate(equiv_index = ifelse(is.na(equiv_index_1_name),
target, equiv_index_1_name)) %>%
group_by(equiv_index) %>%
summarize(swow = sum(swow)) %>%
mutate(swow_normalized = swow/sum(swow),
language = "English") %>%
rename(target = equiv_index)
return(eng_plot)
}
get_nl_plot_data <- function(nl_raw, current_dict, target_word, target_words){
nl_plot <- nl_raw %>%
filter(cue_eng == target_word) %>%
filter(target %in% target_words$dutch) %>%
left_join(current_dict %>% select(dutch, english, equiv_index_1_name) %>% distinct(),
by = c("target" = "dutch")) %>%
select(target, english, swow, equiv_index_1_name) %>%
mutate(equiv_index = ifelse(is.na(equiv_index_1_name),
english, equiv_index_1_name)) %>%
group_by(equiv_index) %>%
summarize(swow = sum(swow)) %>%
mutate(swow_normalized = swow/sum(swow),
language = "Dutch") %>%
rename(target = equiv_index)
return(nl_plot)
}
#### JEALOUSY PLOT
target_word <- "jealousy"
current_dict = my_dict %>%
filter(equiv_index_1 < MIN_RANK,
item == target_word) %>%
select(-equiv_index_1) %>%
distinct()
target_words <- filter(current_dict, item == target_word)
eng_plot <-  get_eng_plot_data(eng_raw, current_dict, target_word, target_words)
nl_plot <- get_nl_plot_data(nl_raw, current_dict, target_word, target_words)
plot_data <- eng_plot %>%
bind_rows(nl_plot) %>%
mutate(target = as.factor(target))  %>%
mutate(target = fct_relevel(target, rev(c("envy", "green/green-eyed", "anger/rage", "hate/hatred", "love", "woman/women/wife",
"emotion", "relationship", "bad", "man", "argument"))),
target = fct_recode(target,
"envy \n (afgunst/nijd)" = "envy",
"green(-eyed) \n (groen)" = "green/green-eyed" ,
"anger/rage \n (woede)" = "anger/rage",
"hate/hatred \n (haat)" = "hate/hatred" ,
"love \n (liefde)" = "love" ,
"woman/wife \n (vrouw(en))" = "woman/women/wife",
"emotion \n (emotie)" = "emotion" ,
"relationship \n (relatie)" = "relationship" ,
"bad \n (slecht)" = "bad",
"man \n (man)" = "man",
"argument \n (ruzie)" = "argument"),
language = fct_rev(language))
pdf("jealousy.pdf", width = 8, height = 4.6)
ggplot(plot_data,
aes(x = target, y = swow_normalized,
fill = target)) +
geom_bar(stat = "identity") +
facet_grid(~language) +
coord_flip() +
theme_minimal() +
theme(legend.position = "none",
axis.text.y = element_text(size = 7)) +
ggtitle("jealousy (jaloezie)") +
ylab("normalized conditional probability") +
xlab("word association")
dev.off()
#### CHEESE PLOT
target_word <- "cheese"
current_dict = my_dict %>%
filter(equiv_index_1 < MIN_RANK,
item == target_word) %>%
select(-equiv_index_1) %>%
distinct()
target_words <- filter(current_dict, item == target_word)
eng_plot <-  get_eng_plot_data(eng_raw, current_dict, target_word, target_words)
nl_plot <- get_nl_plot_data(nl_raw, current_dict, target_word, target_words)
plot_data <- eng_plot %>%
bind_rows(nl_plot) %>%
mutate(target = as.factor(target)) %>%
mutate(target = fct_relevel(target, rev(c("cheddar", "mouse", "food", "brie",
"yellow", "tasty", "orange", "pizza",
"wine", "Swiss", "bread", "holes",
"cow", "Netherlands", "stench"))),
target = fct_recode(target,
"bread \n (brood)" = "bread",
"brie \n (brie)" = "brie" ,
"cheddar \n (cheddar)" = "cheddar",
"cow \n (koe)" = "cow" ,
"food \n (eten)" = "food" ,
"holes \n (gaten/gaatjes)" = "holes" ,
"mouse \n (muis)" = "mouse",
"Netherlands \n (Holland/Netherlands)" = "Netherlands",
"orange \n (oranje)" = "orange",
"pizza \n (pizza)" = "pizza" ,
"stench \n (stank)" = "stench" ,
"Swiss \n (Zwitsers/Zwitserse)" = "Swiss",
"tasty \n (lekker)" = "tasty",
"wine \n (wijn)" = "wine",
"yellow \n (geel)" = "yellow"),
language = fct_rev(language))
pdf("cheese.pdf", width = 8, height = 4.6)
ggplot(plot_data,
aes(x = target, y = swow_normalized,
fill = target)) +
geom_bar(stat = "identity") +
facet_grid(~language) +
coord_flip() +
theme_minimal() +
theme(legend.position = "none",
axis.text.y = element_text(size = 7)) +
ggtitle("cheese (kaas)") +
ylab("normalized conditional probability") +
xlab("word association")
dev.off()
setwd("~/Documents/research/Projects/XTMEM/paper")
